INFO - Dependencies all met for <TaskInstance: ETL_dag.Extract_B1 scheduled__2018-04-14T00:00:00+00:00 [queued]>
INFO - Dependencies all met for <TaskInstance: ETL_dag.Extract_B1 scheduled__2018-04-14T00:00:00+00:00 [queued]>
INFO - 
--------------------------------------------------------------------------------
INFO - Starting attempt 1 of 2
INFO - 
--------------------------------------------------------------------------------
ERROR - Did not find openlineage.yml and OPENLINEAGE_URL is not set
WARNING - Couldn't initialize transport; will print events to console.
INFO - {"eventTime": "2022-11-11T00:36:33.295613Z", "eventType": "START", "inputs": [], "job": {"facets": {}, "name": "ETL_dag.Extract_B1", "namespace": "default"}, "outputs": [], "producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "run": {"facets": {"airflow_runArgs": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "externalTrigger": false}, "airflow_version": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "airflowVersion": "2.4.2+astro.1", "openlineageAirflowVersion": "0.15.1", "operator": "airflow.operators.python.PythonOperator", "taskInfo": {"_BaseOperator__from_mapped": false, "_BaseOperator__init_kwargs": {"dag": {"dag_id": "ETL_dag", "schedule_interval": "@daily"}, "owner": "BROC95", "python_callable": "<function extract at 0x7fe2d4a79c10>", "retries": 1, "retry_delay": "0:05:00", "start_date": "2018-03-01T00:00:00+00:00", "task_id": "Extract_B1"}, "_BaseOperator__instantiated": true, "_dag": {"dag_id": "ETL_dag", "schedule_interval": "@daily"}, "_log": "<Logger airflow.task.operators (INFO)>", "depends_on_past": false, "do_xcom_push": true, "downstream_task_ids": "{'Transform_B1'}", "email_on_failure": true, "email_on_retry": true, "executor_config": {}, "ignore_first_depends_on_past": true, "inlets": [], "op_args": [], "op_kwargs": {}, "outlets": [], "owner": "BROC95", "params": "{}", "pool": "default_pool", "pool_slots": 1, "priority_weight": 1, "python_callable": "<function extract at 0x7fe2d4a79c10>", "queue": "default", "retries": 1, "retry_delay": "0:05:00", "retry_exponential_backoff": false, "show_return_value_in_logs": true, "start_date": "2018-03-01T00:00:00+00:00", "task_group": "<airflow.utils.task_group.TaskGroup object at 0x7fe2f5048040>", "task_id": "Extract_B1", "trigger_rule": "all_success", "upstream_task_ids": "set()", "wait_for_downstream": false, "weight_rule": "downstream"}}, "nominalTime": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/NominalTimeRunFacet", "nominalStartTime": "2018-04-14T00:00:00.000000Z"}, "parent": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/ParentRunFacet", "job": {"name": "ETL_dag", "namespace": "default"}, "run": {"runId": "5899da6f-b4ab-36ad-8bba-a1aeb9389adf"}}, "parentRun": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/ParentRunFacet", "job": {"name": "ETL_dag", "namespace": "default"}, "run": {"runId": "5899da6f-b4ab-36ad-8bba-a1aeb9389adf"}}, "unknownSourceAttribute": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "unknownItems": [{"name": "PythonOperator", "properties": {"_BaseOperator__from_mapped": false, "_BaseOperator__init_kwargs": {"dag": "<<non-serializable: DAG>>", "owner": "BROC95", "python_callable": "<<non-serializable: function>>", "retries": 1, "retry_delay": "<<non-serializable: timedelta>>", "start_date": "<<non-serializable: DateTime>>", "task_id": "Extract_B1"}, "_BaseOperator__instantiated": true, "_dag": "<<non-serializable: DAG>>", "_log": "<<non-serializable: Logger>>", "depends_on_past": false, "do_xcom_push": true, "downstream_task_ids": [], "email_on_failure": true, "email_on_retry": true, "executor_config": {}, "ignore_first_depends_on_past": true, "inlets": [], "op_args": [], "op_kwargs": {}, "outlets": [], "owner": "BROC95", "params": "<<non-serializable: ParamsDict>>", "pool": "default_pool", "pool_slots": 1, "priority_weight": 1, "python_callable": "<<non-serializable: function>>", "queue": "default", "retries": 1, "retry_delay": "<<non-serializable: timedelta>>", "retry_exponential_backoff": false, "show_return_value_in_logs": true, "start_date": "<<non-serializable: DateTime>>", "task_group": "<<non-serializable: TaskGroup>>", "task_id": "Extract_B1", "trigger_rule": "all_success", "upstream_task_ids": [], "wait_for_downstream": false, "weight_rule": "downstream"}, "type": "operator"}]}}, "runId": "3b2c3c7c-c12d-49b7-a047-a20066cf8995"}}
INFO - TaskInstance Details: dag_id=ETL_dag, task_id=Extract_B1, dagrun_id=scheduled__2018-04-14T00:00:00+00:00, map_index=-1, run_start_date=2022-11-11 00:36:33.295613+00:00, try_number=1, job_id=318, op_classpath=airflow.operators.python.PythonOperator
INFO - Executing <Task(PythonOperator): Extract_B1> on 2018-04-14 00:00:00+00:00
INFO - Started process 2395 to run task
INFO - Running: ['airflow', 'tasks', 'run', 'ETL_dag', 'Extract_B1', 'scheduled__2018-04-14T00:00:00+00:00', '--job-id', '318', '--raw', '--subdir', 'DAGS_FOLDER/factory.py', '--cfg-path', '/tmp/tmptmxnzrjv']
INFO - Job 318: Subtask Extract_B1
WARNING - /usr/local/lib/python3.9/site-packages/airflow/configuration.py:545 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
INFO - Running <TaskInstance: ETL_dag.Extract_B1 scheduled__2018-04-14T00:00:00+00:00 [running]> on host 1a42983a4dbb
INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=BROC95
AIRFLOW_CTX_DAG_ID=ETL_dag
AIRFLOW_CTX_TASK_ID=Extract_B1
AIRFLOW_CTX_EXECUTION_DATE=2018-04-14T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-04-14T00:00:00+00:00
INFO - '2022-11-11' - GBUNComahue_dag_elt - GBUNComahue_dag_elt
INFO - '2022-11-11' - GBUNComahue_dag_elt - Extract
INFO - '2022-11-11' - GBUNComahue_dag_elt - Connect: alkemy_db
INFO - '2022-11-11' - airflow.hooks.base - Using connection ID 'alkemy_db' for task execution.
INFO - '2022-11-11' - airflow.hooks.base - Using connection ID 'alkemy_db' for task execution.
WARNING - /usr/local/lib/python3.9/site-packages/airflow/providers/common/sql/hooks/sql.py:176 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
INFO - '2022-11-11' - GBUNComahue_dag_elt -                   universidad  ...        correo_electronico
0  UNIV. NACIONAL DEL COMAHUE  ...  FRANKALEXANDRA@YAHOO.COM
1  UNIV. NACIONAL DEL COMAHUE  ...        TEDWARDS@GMAIL.COM
2  UNIV. NACIONAL DEL COMAHUE  ...       RICHARD76@GMAIL.COM
3  UNIV. NACIONAL DEL COMAHUE  ...          ODUFFY@YAHOO.COM
4  UNIV. NACIONAL DEL COMAHUE  ...     FOSTERCHASE@GMAIL.COM

[5 rows x 8 columns]
INFO - Done. Returned value was: None
INFO - Marking task as SUCCESS. dag_id=ETL_dag, task_id=Extract_B1, execution_date=20180414T000000, start_date=20221111T003633, end_date=20221111T003636
INFO - '2022-11-11' - airflow.listeners.events - session flush listener: added [<TaskInstanceState.SUCCESS: 'success'>] unchanged () deleted ['running'] - <TaskInstance: ETL_dag.Extract_B1 scheduled__2018-04-14T00:00:00+00:00 [success]>
INFO - '2022-11-11' - airflow - OpenLineage listener got notification about task instance success
INFO - '2022-11-11' - root - Using extractor PythonExtractor task_type=PythonOperator airflow_dag_id=ETL_dag task_id=Extract_B1 airflow_run_id=scheduled__2018-04-14T00:00:00+00:00
INFO - '2022-11-11' - root - Found task metadata for operation Extract_B1: TaskMetadata(name='ETL_dag.Extract_B1', inputs=[], outputs=[], run_facets={'unknownSourceAttribute': UnknownOperatorAttributeRunFacet(_producer='https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow', _schemaURL='https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet', unknownItems=[UnknownOperatorInstance(name='PythonOperator', properties={'_BaseOperator__init_kwargs': {'task_id': 'Extract_B1', 'dag': <DAG: ETL_dag>, 'owner': 'BROC95', 'retries': 1, 'retry_delay': datetime.timedelta(seconds=300), 'start_date': DateTime(2018, 3, 1, 0, 0, 0, tzinfo=Timezone('UTC')), 'python_callable': <function extract at 0x7fe2d4a79c10>}, '_BaseOperator__from_mapped': False, 'task_id': 'Extract_B1', 'task_group': <airflow.utils.task_group.TaskGroup object at 0x7fe2f5048040>, 'owner': 'BROC95', 'email': None, 'email_on_retry': True, 'email_on_failure': True, 'execution_timeout': None, 'on_execute_callback': None, 'on_failure_callback': None, 'on_success_callback': None, 'on_retry_callback': None, '_pre_execute_hook': None, '_post_execute_hook': None, 'start_date': DateTime(2018, 3, 1, 0, 0, 0, tzinfo=Timezone('UTC')), 'executor_config': {}, 'run_as_user': None, 'retries': 1, 'queue': 'default', 'pool': 'default_pool', 'pool_slots': 1, 'sla': None, 'trigger_rule': <TriggerRule.ALL_SUCCESS: 'all_success'>, 'depends_on_past': False, 'ignore_first_depends_on_past': True, 'wait_for_downstream': False, 'retry_delay': datetime.timedelta(seconds=300), 'retry_exponential_backoff': False, 'max_retry_delay': None, 'params': {}, 'priority_weight': 1, 'weight_rule': <WeightRule.DOWNSTREAM: 'downstream'>, 'resources': None, 'max_active_tis_per_dag': None, 'do_xcom_push': True, 'doc_md': None, 'doc_json': None, 'doc_yaml': None, 'doc_rst': None, 'doc': None, 'upstream_task_ids': set(), 'downstream_task_ids': {'Transform_B1'}, 'end_date': None, '_dag': <DAG: ETL_dag>, '_log': <Logger airflow.task.operators (INFO)>, 'inlets': [], 'outlets': [], 'python_callable': <function extract at 0x7fe2d4a79c10>, 'op_args': (), 'op_kwargs': {}, 'templates_dict': None, 'show_return_value_in_logs': True, '_BaseOperator__instantiated': True}, type='operator')])}, job_facets={})
INFO - '2022-11-11' - root - Manually extracting lineage metadata from inlets and outlets
INFO - '2022-11-11' - openlineage.client.transport.console - {"eventTime": "2022-11-11T00:36:36.602006Z", "eventType": "COMPLETE", "inputs": [], "job": {"facets": {}, "name": "ETL_dag.Extract_B1", "namespace": "default"}, "outputs": [], "producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "run": {"facets": {"unknownSourceAttribute": {"_producer": "https://github.com/OpenLineage/OpenLineage/tree/0.15.1/integration/airflow", "_schemaURL": "https://raw.githubusercontent.com/OpenLineage/OpenLineage/main/spec/OpenLineage.json#/definitions/BaseFacet", "unknownItems": [{"name": "PythonOperator", "properties": {"_BaseOperator__from_mapped": false, "_BaseOperator__init_kwargs": {"dag": "<<non-serializable: DAG>>", "owner": "BROC95", "python_callable": "<<non-serializable: function>>", "retries": 1, "retry_delay": "<<non-serializable: timedelta>>", "start_date": "<<non-serializable: DateTime>>", "task_id": "Extract_B1"}, "_BaseOperator__instantiated": true, "_dag": "<<non-serializable: DAG>>", "_log": "<<non-serializable: Logger>>", "depends_on_past": false, "do_xcom_push": true, "downstream_task_ids": [], "email_on_failure": true, "email_on_retry": true, "executor_config": {}, "ignore_first_depends_on_past": true, "inlets": [], "op_args": [], "op_kwargs": {}, "outlets": [], "owner": "BROC95", "params": "<<non-serializable: ParamsDict>>", "pool": "default_pool", "pool_slots": 1, "priority_weight": 1, "python_callable": "<<non-serializable: function>>", "queue": "default", "retries": 1, "retry_delay": "<<non-serializable: timedelta>>", "retry_exponential_backoff": false, "show_return_value_in_logs": true, "start_date": "<<non-serializable: DateTime>>", "task_group": "<<non-serializable: TaskGroup>>", "task_id": "Extract_B1", "trigger_rule": "all_success", "upstream_task_ids": [], "wait_for_downstream": false, "weight_rule": "downstream"}, "type": "operator"}]}}, "runId": "3b2c3c7c-c12d-49b7-a047-a20066cf8995"}}
INFO - Task exited with return code 0
INFO - 1 downstream tasks scheduled from follow-on schedule check
